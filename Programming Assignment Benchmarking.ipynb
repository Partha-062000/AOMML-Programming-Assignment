{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pandas\n!pip install matplotlib\n!pip install portalocker\n!pip install torch==2.2.0 torchvision==0.17 torchtext==0.17.0\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:44:46.888179Z","iopub.execute_input":"2025-05-05T17:44:46.888329Z","iopub.status.idle":"2025-05-05T17:47:30.611555Z","shell.execute_reply.started":"2025-05-05T17:44:46.888314Z","shell.execute_reply":"2025-05-05T17:47:30.610854Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.2->pandas) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.5)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: numpy<2,>=1.20 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.20->matplotlib) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.20->matplotlib) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.20->matplotlib) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.20->matplotlib) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.20->matplotlib) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.20->matplotlib) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2,>=1.20->matplotlib) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2,>=1.20->matplotlib) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2,>=1.20->matplotlib) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2,>=1.20->matplotlib) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2,>=1.20->matplotlib) (2024.2.0)\nCollecting portalocker\n  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\nDownloading portalocker-3.1.1-py3-none-any.whl (19 kB)\nInstalling collected packages: portalocker\nSuccessfully installed portalocker-3.1.1\nCollecting torch==2.2.0\n  Downloading torch-2.2.0-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\nCollecting torchvision==0.17\n  Downloading torchvision-0.17.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\nCollecting torchtext==0.17.0\n  Downloading torchtext-0.17.0-cp311-cp311-manylinux1_x86_64.whl.metadata (7.6 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (4.13.1)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (1.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (2025.3.2)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.0)\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.0)\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.0)\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.0)\n  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.0)\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.0)\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.0)\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.0)\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.0)\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.0)\n  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.0)\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==2.2.0 (from torch==2.2.0)\n  Downloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.17) (1.26.4)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.17) (2.32.3)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.17) (11.1.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.17.0) (4.67.1)\nCollecting torchdata==0.7.1 (from torchtext==0.17.0)\n  Downloading torchdata-0.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0) (12.8.93)\nRequirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.7.1->torchtext==0.17.0) (2.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.2.0) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.17) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.17) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.17) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.17) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.17) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.17) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.17) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.17) (3.10)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.17) (2025.1.31)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.2.0) (1.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision==0.17) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision==0.17) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision==0.17) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision==0.17) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision==0.17) (2024.2.0)\nDownloading torch-2.2.0-cp311-cp311-manylinux1_x86_64.whl (755.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchvision-0.17.0-cp311-cp311-manylinux1_x86_64.whl (6.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m100.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchtext-0.17.0-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m104.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torchdata-0.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchdata, torchvision, torchtext\n  Attempting uninstall: triton\n    Found existing installation: triton 3.1.0\n    Uninstalling triton-3.1.0:\n      Successfully uninstalled triton-3.1.0\n  Attempting uninstall: nvidia-nvtx-cu12\n    Found existing installation: nvidia-nvtx-cu12 12.4.127\n    Uninstalling nvidia-nvtx-cu12-12.4.127:\n      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.21.5\n    Uninstalling nvidia-nccl-cu12-2.21.5:\n      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: torch\n    Found existing installation: torch 2.5.1+cu124\n    Uninstalling torch-2.5.1+cu124:\n      Successfully uninstalled torch-2.5.1+cu124\n  Attempting uninstall: torchdata\n    Found existing installation: torchdata 0.11.0\n    Uninstalling torchdata-0.11.0:\n      Successfully uninstalled torchdata-0.11.0\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.20.1+cu124\n    Uninstalling torchvision-0.20.1+cu124:\n      Successfully uninstalled torchvision-0.20.1+cu124\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntorchtune 0.6.1 requires torchdata==0.11.0, but you have torchdata 0.7.1 which is incompatible.\ntorchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 torch-2.2.0 torchdata-0.7.1 torchtext-0.17.0 torchvision-0.17.0 triton-2.2.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nos.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:51:19.334425Z","iopub.execute_input":"2025-05-05T17:51:19.335147Z","iopub.status.idle":"2025-05-05T17:51:19.338927Z","shell.execute_reply.started":"2025-05-05T17:51:19.335115Z","shell.execute_reply":"2025-05-05T17:51:19.338227Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader, Dataset\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport time\nimport pandas as pd\nimport io\nfrom torchtext.datasets import IMDB\nfrom torchtext.data.utils import get_tokenizer\nfrom torchtext.vocab import build_vocab_from_iterator\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torch.utils.data import DataLoader, Dataset\n\ntorch.manual_seed(42)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n        self.fc2 = nn.Linear(128, 10)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(0.5)\n\n    def forward(self, x):\n        x = self.pool(self.relu(self.conv1(x)))  # 28x28 -> 14x14\n        x = self.pool(self.relu(self.conv2(x)))  # 14x14 -> 7x7\n        x = x.view(-1, 64 * 7 * 7)\n        x = self.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)\n        return x\n\n\nclass LSTM(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n        super(LSTM, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n        self.lstm = nn.LSTM(embedding_dim, \n                           hidden_dim, \n                           num_layers=n_layers, \n                           bidirectional=True, \n                           dropout=dropout if n_layers > 1 else 0,\n                           batch_first=True)\n        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, text):\n        embedded = self.dropout(self.embedding(text))\n        output, (hidden, cell) = self.lstm(embedded)\n        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n        return self.fc(hidden)\n\n# Helper functions for IMDB dataset\ndef yield_tokens(data_iter, tokenizer):\n    for _, text in data_iter:\n        yield tokenizer(text)\n\ndef collate_batch(batch):\n    text_list, label_list = [], []\n    for (_label, _text) in batch:\n        # Ensure label is either 0 or 1 (map 'pos' to 1, 'neg' to 0)\n        if isinstance(_label, str):\n            label = 1 if _label == 'pos' else 0\n        else:\n            # Make sure it's within valid range (0 or 1)\n            label = int(_label) % 2  \n        \n        label_list.append(label)\n        processed_text = torch.tensor(text_vocab(tokenizer(_text)), dtype=torch.int64)\n        text_list.append(processed_text)\n\n    text_list = pad_sequence(text_list, batch_first=True, padding_value=pad_idx)\n    label_list = torch.tensor(label_list, dtype=torch.int64)\n    return text_list, label_list\n\n# Function to train models\ndef train_model(model, optimizer_name, train_loader, val_loader, criterion, epochs, model_type):\n    if optimizer_name == 'Adam':\n        optimizer = optim.Adam(model.parameters(), lr=0.001)\n    elif optimizer_name == 'RMSprop':\n        optimizer = optim.RMSprop(model.parameters(), lr=0.001)\n    elif optimizer_name == 'SGD':\n        optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n    elif optimizer_name == 'Adagrad':\n        optimizer = optim.Adagrad(model.parameters(), lr=0.01)\n    \n    model = model.to(device)\n    criterion = criterion.to(device)\n    \n    train_losses = []\n    val_accuracies = []\n    \n    start_time = time.time()\n    \n    for epoch in range(epochs):\n        # Training phase\n        model.train()\n        running_loss = 0.0\n        for i, data in enumerate(train_loader):\n            if model_type == 'CNN':\n                inputs, labels = data\n            else:  # RNN\n                inputs, labels = data\n            \n            inputs, labels = inputs.to(device), labels.to(device)\n            \n            # Debugging: Check label range\n            if model_type == 'LSTM':\n                if torch.any(labels < 0) or torch.any(labels >= 2):  # For binary classification\n                    print(f\"Warning: Labels out of range found: {labels}\")\n                    # Fix labels to be within range\n                    labels = torch.clamp(labels, 0, 1)\n            \n            optimizer.zero_grad()\n            outputs = model(inputs)\n            \n            if model_type == 'CNN':\n                loss = criterion(outputs, labels)\n            else:  # RNN\n                loss = criterion(outputs, labels)\n                \n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss.item()\n            \n            # Print progress every 100 batches\n            if (i + 1) % 100 == 0:\n                print(f'Epoch [{epoch+1}/{epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n        \n        epoch_loss = running_loss / len(train_loader)\n        train_losses.append(epoch_loss)\n        \n        # Validation phase\n        model.eval()\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for data in val_loader:\n                if model_type == 'CNN':\n                    inputs, labels = data\n                else:  # RNN\n                    inputs, labels = data\n                    # Ensure labels are in valid range\n                    if torch.any(labels < 0) or torch.any(labels >= 2):  # For binary classification\n                        labels = torch.clamp(labels, 0, 1)\n                \n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)\n                _, predicted = torch.max(outputs.data, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n        \n        accuracy = 100 * correct / total\n        val_accuracies.append(accuracy)\n        \n        print(f'Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Validation Accuracy: {accuracy:.2f}%')\n    \n    training_time = time.time() - start_time\n    print(f'Training complete in {training_time:.2f} seconds')\n    \n    # Compute final metrics\n    model.eval()\n    correct = 0\n    total = 0\n    true_positives = 0\n    false_positives = 0\n    false_negatives = 0\n    \n    # For multi-class (MNIST), we'll compute precision and recall for each class\n    if model_type == 'CNN':\n        num_classes = 10\n        confusion_matrix = np.zeros((num_classes, num_classes), dtype=int)\n    else:  # For binary classification (IMDB)\n        num_classes = 2\n        confusion_matrix = np.zeros((num_classes, num_classes), dtype=int)\n    \n    with torch.no_grad():\n        for data in val_loader:\n            if model_type == 'CNN':\n                images, labels = data\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n            else:  # RNN\n                texts, labels = data\n                # Ensure labels are in valid range\n                if torch.any(labels < 0) or torch.any(labels >= 2):\n                    labels = torch.clamp(labels, 0, 1)\n                texts, labels = texts.to(device), labels.to(device)\n                outputs = model(texts)\n            \n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            \n            # Update confusion matrix\n            for t, p in zip(labels.view(-1), predicted.view(-1)):\n                confusion_matrix[t.long(), p.long()] += 1\n    \n    accuracy = 100 * correct / total\n    \n    # Calculate precision, recall, and F1 score\n    precisions = []\n    recalls = []\n    f1_scores = []\n    \n    for i in range(num_classes):\n        true_pos = confusion_matrix[i, i]\n        false_pos = confusion_matrix[:, i].sum() - true_pos\n        false_neg = confusion_matrix[i, :].sum() - true_pos\n        \n        if true_pos + false_pos == 0:\n            precision = 0\n        else:\n            precision = true_pos / (true_pos + false_pos)\n        \n        if true_pos + false_neg == 0:\n            recall = 0\n        else:\n            recall = true_pos / (true_pos + false_neg)\n        \n        if precision + recall == 0:\n            f1 = 0\n        else:\n            f1 = 2 * precision * recall / (precision + recall)\n        \n        precisions.append(precision)\n        recalls.append(recall)\n        f1_scores.append(f1)\n    \n    # For RNN (binary classification), report macro-averaged metrics\n    if model_type == 'LSTM':\n        precision = sum(precisions) / len(precisions)\n        recall = sum(recalls) / len(recalls)\n        f1 = sum(f1_scores) / len(f1_scores)\n    else:  # For CNN, report weighted metrics\n        total_samples_per_class = confusion_matrix.sum(axis=1)\n        precision = sum(p * s for p, s in zip(precisions, total_samples_per_class)) / total_samples_per_class.sum()\n        recall = sum(r * s for r, s in zip(recalls, total_samples_per_class)) / total_samples_per_class.sum()\n        f1 = sum(f * s for f, s in zip(f1_scores, total_samples_per_class)) / total_samples_per_class.sum()\n    \n    metrics = {\n        'optimizer': optimizer_name,\n        'model_type': model_type,\n        'accuracy': accuracy,\n        'precision': precision * 100,\n        'recall': recall * 100,\n        'f1_score': f1 * 100,\n        'training_time': training_time,\n        'train_losses': train_losses,\n        'val_accuracies': val_accuracies\n    }\n    \n    return metrics\n\n# Function to plot results\ndef plot_results(metrics_list, title_prefix):\n    # Plot training loss\n    plt.figure(figsize=(14, 6))\n    plt.subplot(1, 2, 1)\n    for metrics in metrics_list:\n        plt.plot(metrics['train_losses'], label=f\"{metrics['optimizer']}\")\n    plt.title(f'{title_prefix} - Training Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    \n    # Plot validation accuracy\n    plt.subplot(1, 2, 2)\n    for metrics in metrics_list:\n        plt.plot(metrics['val_accuracies'], label=f\"{metrics['optimizer']}\")\n    plt.title(f'{title_prefix} - Validation Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy (%)')\n    plt.legend()\n    plt.tight_layout()\n    \n    # Save the plot\n    plt.savefig(f\"{title_prefix.lower().replace(' ', '_')}_plots.png\")\n    plt.show()\n    plt.close()\n\n# Function to display metrics comparison\ndef display_metrics_comparison(metrics_list, model_type):\n    df = pd.DataFrame([\n        {\n            'Optimizer': m['optimizer'],\n            'Accuracy (%)': f\"{m['accuracy']:.2f}\",\n            'Precision (%)': f\"{m['precision']:.2f}\",\n            'Recall (%)': f\"{m['recall']:.2f}\",\n            'F1 Score (%)': f\"{m['f1_score']:.2f}\",\n            'Training Time (s)': f\"{m['training_time']:.2f}\"\n        }\n        for m in metrics_list\n    ])\n    \n    print(f\"\\nMetrics Comparison for {model_type}:\")\n    print(df.to_string(index=False))\n    return df\n\n# Main execution\ndef main():\n    # MNIST dataset\n    transform = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.1307,), (0.3081,))\n    ])\n    \n    # Load MNIST dataset\n    train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n    test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n    \n    # Split training set into training and validation\n    train_size = int(0.8 * len(train_dataset))\n    val_size = len(train_dataset) - train_size\n    train_mnist, val_mnist = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n    \n    train_loader_mnist = DataLoader(train_mnist, batch_size=64, shuffle=True)\n    val_loader_mnist = DataLoader(val_mnist, batch_size=64, shuffle=False)\n    test_loader_mnist = DataLoader(test_dataset, batch_size=64, shuffle=False)\n    \n    # Load IMDB dataset\n    global tokenizer, text_vocab, pad_idx\n    tokenizer = get_tokenizer('basic_english')\n    \n    # Load IMDB dataset\n    train_iter = IMDB(split='train')\n    test_iter = IMDB(split='test')\n    \n    # Create vocabulary\n    text_vocab = build_vocab_from_iterator(\n        yield_tokens(train_iter, tokenizer),\n        min_freq=5,\n        specials=['<unk>', '<pad>']\n    )\n    text_vocab.set_default_index(text_vocab['<unk>'])\n    \n    # Define padding index\n    pad_idx = text_vocab['<pad>']\n    \n    # Reset iterators\n    train_iter, test_iter = IMDB(split='train'), IMDB(split='test')\n    \n    # Convert to list for easier splitting\n    train_data = list(train_iter)\n    test_data = list(test_iter)\n    \n    # Print IMDB dataset sample to debug\n    print(\"IMDB sample entries:\")\n    for i in range(min(5, len(train_data))):\n        print(f\"Entry {i}: Label={train_data[i][0]}, Text preview: {train_data[i][1][:50]}...\")\n    \n    # Split train data into train and validation\n    train_size = int(0.8 * len(train_data))\n    val_size = len(train_data) - train_size\n    train_imdb, val_imdb = torch.utils.data.random_split(train_data, [train_size, val_size])\n    \n    # Create data loaders\n    train_loader_imdb = DataLoader(train_imdb, batch_size=32, shuffle=True, collate_fn=collate_batch)\n    val_loader_imdb = DataLoader(val_imdb, batch_size=32, shuffle=False, collate_fn=collate_batch)\n    test_loader_imdb = DataLoader(test_data, batch_size=32, shuffle=False, collate_fn=collate_batch)\n    \n    # Check first batch of IMDB data to ensure labels are correct\n    print(\"Checking first IMDB batch:\")\n    for texts, labels in train_loader_imdb:\n        print(f\"Text batch shape: {texts.shape}\")\n        print(f\"Label batch: {labels}\")\n        print(f\"Label min: {labels.min()}, Label max: {labels.max()}\")\n        break\n    \n    # Define CNN model hyperparameters\n    cnn_epochs = 5\n    \n    # Define RNN model hyperparameters\n    vocab_size = len(text_vocab)\n    embedding_dim = 100\n    hidden_dim = 256\n    output_dim = 2  # Binary classification for sentiment\n    n_layers = 2\n    dropout = 0.5\n    rnn_epochs = 3\n    \n    # Optimizers to test\n    optimizers = ['Adam', 'RMSprop', 'SGD', 'Adagrad']\n    \n    # Train CNN models with different optimizers\n    cnn_metrics = []\n    for opt in optimizers:\n        print(f\"\\n=== Training CNN with {opt} optimizer ===\")\n        model = CNN().to(device)\n        criterion = nn.CrossEntropyLoss()\n        metrics = train_model(model, opt, train_loader_mnist, val_loader_mnist, criterion, cnn_epochs, 'CNN')\n        cnn_metrics.append(metrics)\n    \n    # Train RNN models with different optimizers\n    rnn_metrics = []\n    for opt in optimizers:\n        print(f\"\\n=== Training LSTM with {opt} optimizer ===\")\n        model = LSTM(vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout).to(device)\n        criterion = nn.CrossEntropyLoss()\n        metrics = train_model(model, opt, train_loader_imdb, val_loader_imdb, criterion, rnn_epochs, 'LSTM')\n        rnn_metrics.append(metrics)\n    \n    # Plot results\n    plot_results(cnn_metrics, \"CNN on MNIST\")\n    plot_results(rnn_metrics, \"LSTM on IMDB\")\n    \n    # Display metrics comparison\n    cnn_df = display_metrics_comparison(cnn_metrics, \"CNN on MNIST\")\n    rnn_df = display_metrics_comparison(rnn_metrics, \"LSTM on IMDB\")\n    \n    return cnn_df, rnn_df\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:51:23.500198Z","iopub.execute_input":"2025-05-05T17:51:23.500717Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nIMDB sample entries:\nEntry 0: Label=1, Text preview: I rented I AM CURIOUS-YELLOW from my video store b...\nEntry 1: Label=1, Text preview: \"I Am Curious: Yellow\" is a risible and pretentiou...\nEntry 2: Label=1, Text preview: If only to avoid making this type of film in the f...\nEntry 3: Label=1, Text preview: This film was probably inspired by Godard's Mascul...\nEntry 4: Label=1, Text preview: Oh, brother...after hearing about this ridiculous ...\nChecking first IMDB batch:\nText batch shape: torch.Size([32, 930])\nLabel batch: tensor([0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n        0, 0, 1, 0, 0, 1, 0, 0])\nLabel min: 0, Label max: 1\n\n=== Training CNN with Adam optimizer ===\nEpoch [1/5], Step [100/750], Loss: 0.5253\nEpoch [1/5], Step [200/750], Loss: 0.3182\nEpoch [1/5], Step [300/750], Loss: 0.1993\nEpoch [1/5], Step [400/750], Loss: 0.1320\nEpoch [1/5], Step [500/750], Loss: 0.1762\nEpoch [1/5], Step [600/750], Loss: 0.0994\nEpoch [1/5], Step [700/750], Loss: 0.1895\nEpoch 1/5, Loss: 0.2661, Validation Accuracy: 98.03%\nEpoch [2/5], Step [100/750], Loss: 0.2949\nEpoch [2/5], Step [200/750], Loss: 0.0368\nEpoch [2/5], Step [300/750], Loss: 0.1243\nEpoch [2/5], Step [400/750], Loss: 0.1069\nEpoch [2/5], Step [500/750], Loss: 0.0593\nEpoch [2/5], Step [600/750], Loss: 0.0522\nEpoch [2/5], Step [700/750], Loss: 0.0455\nEpoch 2/5, Loss: 0.0981, Validation Accuracy: 98.31%\nEpoch [3/5], Step [100/750], Loss: 0.0296\nEpoch [3/5], Step [200/750], Loss: 0.0778\nEpoch [3/5], Step [300/750], Loss: 0.0143\nEpoch [3/5], Step [400/750], Loss: 0.0175\nEpoch [3/5], Step [500/750], Loss: 0.1183\nEpoch [3/5], Step [600/750], Loss: 0.0131\nEpoch [3/5], Step [700/750], Loss: 0.0159\nEpoch 3/5, Loss: 0.0737, Validation Accuracy: 98.73%\nEpoch [4/5], Step [100/750], Loss: 0.0373\nEpoch [4/5], Step [200/750], Loss: 0.1207\nEpoch [4/5], Step [300/750], Loss: 0.0650\nEpoch [4/5], Step [400/750], Loss: 0.1075\nEpoch [4/5], Step [500/750], Loss: 0.0288\nEpoch [4/5], Step [600/750], Loss: 0.0760\nEpoch [4/5], Step [700/750], Loss: 0.0343\nEpoch 4/5, Loss: 0.0639, Validation Accuracy: 98.85%\nEpoch [5/5], Step [100/750], Loss: 0.0384\nEpoch [5/5], Step [200/750], Loss: 0.0321\nEpoch [5/5], Step [300/750], Loss: 0.0373\nEpoch [5/5], Step [400/750], Loss: 0.0773\nEpoch [5/5], Step [500/750], Loss: 0.0137\nEpoch [5/5], Step [600/750], Loss: 0.0457\nEpoch [5/5], Step [700/750], Loss: 0.1509\nEpoch 5/5, Loss: 0.0505, Validation Accuracy: 98.98%\nTraining complete in 67.19 seconds\n\n=== Training CNN with RMSprop optimizer ===\nEpoch [1/5], Step [100/750], Loss: 0.1924\nEpoch [1/5], Step [200/750], Loss: 0.2900\nEpoch [1/5], Step [300/750], Loss: 0.2273\nEpoch [1/5], Step [400/750], Loss: 0.3855\nEpoch [1/5], Step [500/750], Loss: 0.1726\nEpoch [1/5], Step [600/750], Loss: 0.1145\nEpoch [1/5], Step [700/750], Loss: 0.1155\nEpoch 1/5, Loss: 0.2404, Validation Accuracy: 97.89%\nEpoch [2/5], Step [100/750], Loss: 0.0643\nEpoch [2/5], Step [200/750], Loss: 0.0766\nEpoch [2/5], Step [300/750], Loss: 0.1145\nEpoch [2/5], Step [400/750], Loss: 0.0471\nEpoch [2/5], Step [500/750], Loss: 0.0092\nEpoch [2/5], Step [600/750], Loss: 0.0331\nEpoch [2/5], Step [700/750], Loss: 0.0190\nEpoch 2/5, Loss: 0.0833, Validation Accuracy: 98.43%\nEpoch [3/5], Step [100/750], Loss: 0.0174\nEpoch [3/5], Step [200/750], Loss: 0.1383\nEpoch [3/5], Step [300/750], Loss: 0.0122\nEpoch [3/5], Step [400/750], Loss: 0.0657\nEpoch [3/5], Step [500/750], Loss: 0.0430\nEpoch [3/5], Step [600/750], Loss: 0.0653\nEpoch [3/5], Step [700/750], Loss: 0.0214\nEpoch 3/5, Loss: 0.0619, Validation Accuracy: 98.71%\nEpoch [4/5], Step [100/750], Loss: 0.1007\nEpoch [4/5], Step [200/750], Loss: 0.0193\nEpoch [4/5], Step [300/750], Loss: 0.0153\nEpoch [4/5], Step [400/750], Loss: 0.0103\nEpoch [4/5], Step [500/750], Loss: 0.0140\nEpoch [4/5], Step [600/750], Loss: 0.1275\nEpoch [4/5], Step [700/750], Loss: 0.0222\nEpoch 4/5, Loss: 0.0511, Validation Accuracy: 98.75%\nEpoch [5/5], Step [100/750], Loss: 0.0046\nEpoch [5/5], Step [200/750], Loss: 0.0284\nEpoch [5/5], Step [300/750], Loss: 0.0194\nEpoch [5/5], Step [400/750], Loss: 0.0592\nEpoch [5/5], Step [500/750], Loss: 0.0278\nEpoch [5/5], Step [600/750], Loss: 0.0176\nEpoch [5/5], Step [700/750], Loss: 0.1350\nEpoch 5/5, Loss: 0.0460, Validation Accuracy: 98.79%\nTraining complete in 65.65 seconds\n\n=== Training CNN with SGD optimizer ===\nEpoch [1/5], Step [100/750], Loss: 0.4992\nEpoch [1/5], Step [200/750], Loss: 0.1950\nEpoch [1/5], Step [300/750], Loss: 0.0906\nEpoch [1/5], Step [400/750], Loss: 0.1529\nEpoch [1/5], Step [500/750], Loss: 0.2116\nEpoch [1/5], Step [600/750], Loss: 0.0847\nEpoch [1/5], Step [700/750], Loss: 0.0984\nEpoch 1/5, Loss: 0.3341, Validation Accuracy: 97.47%\nEpoch [2/5], Step [100/750], Loss: 0.0486\nEpoch [2/5], Step [200/750], Loss: 0.2230\nEpoch [2/5], Step [300/750], Loss: 0.1135\nEpoch [2/5], Step [400/750], Loss: 0.0799\nEpoch [2/5], Step [500/750], Loss: 0.1216\nEpoch [2/5], Step [600/750], Loss: 0.0981\nEpoch [2/5], Step [700/750], Loss: 0.0898\nEpoch 2/5, Loss: 0.1017, Validation Accuracy: 98.39%\nEpoch [3/5], Step [100/750], Loss: 0.1535\nEpoch [3/5], Step [200/750], Loss: 0.0386\nEpoch [3/5], Step [300/750], Loss: 0.0778\nEpoch [3/5], Step [400/750], Loss: 0.0116\nEpoch [3/5], Step [500/750], Loss: 0.1049\nEpoch [3/5], Step [600/750], Loss: 0.1137\nEpoch [3/5], Step [700/750], Loss: 0.1065\nEpoch 3/5, Loss: 0.0742, Validation Accuracy: 98.63%\nEpoch [4/5], Step [100/750], Loss: 0.0615\nEpoch [4/5], Step [200/750], Loss: 0.0483\nEpoch [4/5], Step [300/750], Loss: 0.0304\nEpoch [4/5], Step [400/750], Loss: 0.0164\nEpoch [4/5], Step [500/750], Loss: 0.0614\nEpoch [4/5], Step [600/750], Loss: 0.2026\nEpoch [4/5], Step [700/750], Loss: 0.0301\nEpoch 4/5, Loss: 0.0582, Validation Accuracy: 98.79%\nEpoch [5/5], Step [100/750], Loss: 0.1556\nEpoch [5/5], Step [200/750], Loss: 0.0207\nEpoch [5/5], Step [300/750], Loss: 0.0379\nEpoch [5/5], Step [400/750], Loss: 0.1043\nEpoch [5/5], Step [500/750], Loss: 0.0541\nEpoch [5/5], Step [600/750], Loss: 0.0728\nEpoch [5/5], Step [700/750], Loss: 0.0052\nEpoch 5/5, Loss: 0.0494, Validation Accuracy: 98.73%\nTraining complete in 63.01 seconds\n\n=== Training CNN with Adagrad optimizer ===\nEpoch [1/5], Step [100/750], Loss: 0.1675\nEpoch [1/5], Step [200/750], Loss: 0.3027\nEpoch [1/5], Step [300/750], Loss: 0.0651\nEpoch [1/5], Step [400/750], Loss: 0.2119\nEpoch [1/5], Step [500/750], Loss: 0.3629\nEpoch [1/5], Step [600/750], Loss: 0.1211\nEpoch [1/5], Step [700/750], Loss: 0.0788\nEpoch 1/5, Loss: 0.2266, Validation Accuracy: 97.64%\nEpoch [2/5], Step [100/750], Loss: 0.0641\nEpoch [2/5], Step [200/750], Loss: 0.0791\nEpoch [2/5], Step [300/750], Loss: 0.0949\nEpoch [2/5], Step [400/750], Loss: 0.1247\nEpoch [2/5], Step [500/750], Loss: 0.1330\nEpoch [2/5], Step [600/750], Loss: 0.0686\nEpoch [2/5], Step [700/750], Loss: 0.2210\nEpoch 2/5, Loss: 0.0959, Validation Accuracy: 98.20%\nEpoch [3/5], Step [100/750], Loss: 0.0320\nEpoch [3/5], Step [200/750], Loss: 0.0168\nEpoch [3/5], Step [300/750], Loss: 0.0722\nEpoch [3/5], Step [400/750], Loss: 0.0059\nEpoch [3/5], Step [500/750], Loss: 0.0422\nEpoch [3/5], Step [600/750], Loss: 0.1170\nEpoch [3/5], Step [700/750], Loss: 0.0555\nEpoch 3/5, Loss: 0.0751, Validation Accuracy: 98.47%\nEpoch [4/5], Step [100/750], Loss: 0.0436\nEpoch [4/5], Step [200/750], Loss: 0.0374\nEpoch [4/5], Step [300/750], Loss: 0.0693\nEpoch [4/5], Step [400/750], Loss: 0.1090\nEpoch [4/5], Step [500/750], Loss: 0.0141\nEpoch [4/5], Step [600/750], Loss: 0.0273\nEpoch [4/5], Step [700/750], Loss: 0.1310\nEpoch 4/5, Loss: 0.0628, Validation Accuracy: 98.59%\nEpoch [5/5], Step [100/750], Loss: 0.0484\nEpoch [5/5], Step [200/750], Loss: 0.0746\nEpoch [5/5], Step [300/750], Loss: 0.0791\nEpoch [5/5], Step [400/750], Loss: 0.1538\nEpoch [5/5], Step [500/750], Loss: 0.0810\nEpoch [5/5], Step [600/750], Loss: 0.1207\nEpoch [5/5], Step [700/750], Loss: 0.0168\nEpoch 5/5, Loss: 0.0549, Validation Accuracy: 98.75%\nTraining complete in 61.95 seconds\n\n=== Training LSTM with Adam optimizer ===\nEpoch [1/3], Step [100/625], Loss: 0.6947\nEpoch [1/3], Step [200/625], Loss: 0.6611\nEpoch [1/3], Step [300/625], Loss: 0.6589\nEpoch [1/3], Step [400/625], Loss: 0.7581\nEpoch [1/3], Step [500/625], Loss: 0.6868\nEpoch [1/3], Step [600/625], Loss: 0.6914\nEpoch 1/3, Loss: 0.6836, Validation Accuracy: 56.04%\nEpoch [2/3], Step [100/625], Loss: 0.5481\nEpoch [2/3], Step [200/625], Loss: 0.6133\nEpoch [2/3], Step [300/625], Loss: 0.7862\nEpoch [2/3], Step [400/625], Loss: 0.6677\nEpoch [2/3], Step [500/625], Loss: 0.6537\nEpoch [2/3], Step [600/625], Loss: 0.6011\nEpoch 2/3, Loss: 0.6383, Validation Accuracy: 61.36%\nEpoch [3/3], Step [100/625], Loss: 0.5035\nEpoch [3/3], Step [200/625], Loss: 0.7725\nEpoch [3/3], Step [300/625], Loss: 0.5810\nEpoch [3/3], Step [400/625], Loss: 0.4187\nEpoch [3/3], Step [500/625], Loss: 0.3597\nEpoch [3/3], Step [600/625], Loss: 0.6733\nEpoch 3/3, Loss: 0.5440, Validation Accuracy: 79.78%\nTraining complete in 780.49 seconds\n\n=== Training LSTM with RMSprop optimizer ===\nEpoch [1/3], Step [100/625], Loss: 0.6952\nEpoch [1/3], Step [200/625], Loss: 0.6798\nEpoch [1/3], Step [300/625], Loss: 0.7308\nEpoch [1/3], Step [400/625], Loss: 0.7012\nEpoch [1/3], Step [500/625], Loss: 0.6981\nEpoch [1/3], Step [600/625], Loss: 0.6587\nEpoch 1/3, Loss: 0.6922, Validation Accuracy: 57.72%\nEpoch [2/3], Step [100/625], Loss: 0.6915\nEpoch [2/3], Step [200/625], Loss: 0.6584\nEpoch [2/3], Step [300/625], Loss: 0.5642\nEpoch [2/3], Step [400/625], Loss: 0.7161\nEpoch [2/3], Step [500/625], Loss: 0.6532\nEpoch [2/3], Step [600/625], Loss: 0.6781\nEpoch 2/3, Loss: 0.6705, Validation Accuracy: 64.36%\nEpoch [3/3], Step [100/625], Loss: 0.6570\nEpoch [3/3], Step [200/625], Loss: 0.6878\nEpoch [3/3], Step [300/625], Loss: 0.6195\nEpoch [3/3], Step [400/625], Loss: 0.5836\nEpoch [3/3], Step [500/625], Loss: 0.6771\nEpoch [3/3], Step [600/625], Loss: 0.6419\nEpoch 3/3, Loss: 0.6390, Validation Accuracy: 64.94%\nTraining complete in 780.09 seconds\n\n=== Training LSTM with SGD optimizer ===\nEpoch [1/3], Step [100/625], Loss: 0.6958\nEpoch [1/3], Step [200/625], Loss: 0.6880\nEpoch [1/3], Step [300/625], Loss: 0.6924\nEpoch [1/3], Step [400/625], Loss: 0.6916\nEpoch [1/3], Step [500/625], Loss: 0.6945\nEpoch [1/3], Step [600/625], Loss: 0.6900\nEpoch 1/3, Loss: 0.6927, Validation Accuracy: 50.40%\nEpoch [2/3], Step [100/625], Loss: 0.6633\nEpoch [2/3], Step [200/625], Loss: 0.7399\nEpoch [2/3], Step [300/625], Loss: 0.7200\nEpoch [2/3], Step [400/625], Loss: 0.6750\nEpoch [2/3], Step [500/625], Loss: 0.6803\nEpoch [2/3], Step [600/625], Loss: 0.6857\nEpoch 2/3, Loss: 0.6902, Validation Accuracy: 54.54%\nEpoch [3/3], Step [100/625], Loss: 0.7110\nEpoch [3/3], Step [200/625], Loss: 0.6988\nEpoch [3/3], Step [300/625], Loss: 0.6884\nEpoch [3/3], Step [400/625], Loss: 0.6837\nEpoch [3/3], Step [500/625], Loss: 0.7168\nEpoch [3/3], Step [600/625], Loss: 0.6753\nEpoch 3/3, Loss: 0.6861, Validation Accuracy: 56.38%\nTraining complete in 770.00 seconds\n\n=== Training LSTM with Adagrad optimizer ===\nEpoch [1/3], Step [100/625], Loss: 0.6936\nEpoch [1/3], Step [200/625], Loss: 0.6562\nEpoch [1/3], Step [300/625], Loss: 0.7108\nEpoch [1/3], Step [400/625], Loss: 0.6611\nEpoch [1/3], Step [500/625], Loss: 0.6799\nEpoch [1/3], Step [600/625], Loss: 0.5709\nEpoch 1/3, Loss: 0.6825, Validation Accuracy: 64.80%\nEpoch [2/3], Step [100/625], Loss: 0.6491\nEpoch [2/3], Step [200/625], Loss: 0.6832\nEpoch [2/3], Step [300/625], Loss: 0.7138\nEpoch [2/3], Step [400/625], Loss: 0.7135\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}